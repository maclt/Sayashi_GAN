{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sayashi3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VyrLZhRLaKfe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbDA5PKRaWvN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/drive/folders/<ID>\n",
        "dir_id = \"1DLqYGQKx4tMHDEy85lVfgfxHLC-RNRqJ\"\n",
        "\n",
        "# フォルダ内にあるファイル名とファイルIDを表示する\n",
        "file_list = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % dir_id}).GetList()\n",
        "for f in file_list:\n",
        "  print(\"name: \" + f[\"title\"] + \", id: \" + f[\"id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uL0pZihDaa8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 鞘師のデータを取得\n",
        "id = '1h7UdJxcTZjg-KfIHk1NfjAa3dCKAd4Co'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('this_is_sayashi.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-lGF8kBdV8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir this_is_sayashi\n",
        "!unzip this_is_sayashi.zip -d this_is_sayashi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PoFn-rohuIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -r this_is_sayashi/__MACOSX/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "omVoZdRGhziw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 道重のデータを取得\n",
        "id = '1SvOeSS3iufFJ0w50ruf0BWFyjRNebMQL'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('this_is_sayumi.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bHFg14Gh-E2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir this_is_sayumi\n",
        "! unzip this_is_sayumi.zip -d this_is_sayumi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVG19RP7h-0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -r this_is_sayumi/__MACOSX/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i4PXs7VZiDVY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 佳林のデータを取得\n",
        "id = '1bCAcif-NB_H76mYDW4cGKnGB4QoiM8IH'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('this_is_karin.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0tZDp0lKiDc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir this_is_karin\n",
        "! unzip this_is_karin.zip -d this_is_karin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdp8qmCxiDn8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -r this_is_karin/__MACOSX/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKfP0jAviMRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, list_pictures, load_img\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w4NpMptriMYD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.core import Reshape, Dense, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "def Generator():\n",
        "    nch = 200\n",
        "    model_input = Input(shape=[100])\n",
        "    x = Dense(nch*50*50, kernel_initializer='glorot_normal')(model_input) # 100 -> 200*50*50\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Reshape( [50, 50, nch] )(x) # 200*50*50 -> 50x50x200 (width)x(height)x(channel)\n",
        "    x = UpSampling2D(size=(2, 2))(x) # 50x50x200 -> 100x100x200\n",
        "    x = Conv2D(int(nch/2), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x) # 100x100x200 -> 100x100x100\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(int(nch/4), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x) # 100x100x100 -> 100x100x50\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(3, (1, 1), padding='same', kernel_initializer='glorot_uniform')(x) # 100x100x50 -> 100x100x3\n",
        "    model_output = Activation('sigmoid')(x)\n",
        "    model = Model(model_input, model_output)\n",
        "    # model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYo-LOadiMcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "\n",
        "def Discriminator(shape, dropout_rate=0.25, opt=Adam(lr=1e-4)):\n",
        "    model_input = Input(shape=shape) # 100x100x3\n",
        "    x = Conv2D(256, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(model_input) # 100x100x3 -> 50x50x256\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Conv2D(512, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(x) # 50x50x256 -> 25x25x512\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Flatten()(x) # 25x25x512 -> 25*25*512\n",
        "    x = Dense(256)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    model_output = Dense(2,activation='softmax')(x) # 256 -> 2\n",
        "    model = Model(model_input, model_output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iVtGn-WqiMVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "def combined_network(generator, discriminator, opt=Adam(lr=1e-3)):\n",
        "    gan_input = Input(shape=[100])\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    model = Model(gan_input, gan_output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "    # model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S34Q3PbgpEdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_trainable(net, val):\n",
        "    net.trainable = val\n",
        "    for l in net.layers:\n",
        "        l.trainable = val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z-Gr2ioDpFIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(step=3000, BATCH_SIZE=128):\n",
        "    for e in tqdm(range(step)):\n",
        "        # 1. バッチの学習で利用する画像の選択 \n",
        "        # バッチサイズの分だけランダムに画像を選択\n",
        "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE),:,:,:]\n",
        "        \n",
        "        # バッチサイズの分だけランダムにノイズを生成し、generatorにより画像を生成\n",
        "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
        "        generated_images = generator.predict(noise_gen)\n",
        "        \n",
        "        # 2. Discriminatorの学習をonに切り替える\n",
        "        # Discriminatorが学習するように変更\n",
        "        make_trainable(discriminator,True)\n",
        "        \n",
        "        # 3. Generatorによる生成画像を用いてDiscriminatorの学習\n",
        "        # X = (バッチサイズ分のデータセットの画像, バッチサイズ分の生成画像)\n",
        "        X = np.concatenate((image_batch, generated_images))\n",
        "        \n",
        "        # y = (バッチサイズ分のTrue(本物), バッチサイズ分のFalse(偽物))\n",
        "        y = np.zeros([2*BATCH_SIZE,2])\n",
        "        y[:BATCH_SIZE,1] = 1\n",
        "        y[BATCH_SIZE:,0] = 1      \n",
        "        \n",
        "        # Discriminatorのtrain\n",
        "        discriminator.train_on_batch(X,y)\n",
        "        \n",
        "        # 4. Discriminatorの学習をoffに切り替える\n",
        "        # Discriminatorが学習しないように変更\n",
        "        make_trainable(discriminator,False)\n",
        "    \n",
        "        # 5. Generatorの学習\n",
        "        # バッチサイズの分だけランダムにノイズを生成\n",
        "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
        "        \n",
        "        # y = (バッチサイズ分のTrue(本物))\n",
        "        # 実際には生成した画像なのでDiscriminatorとしては偽物と判断すべきだが、Genaratorの学習なので生成した画像を本物と判断するように学習させる\n",
        "        y2 = np.zeros([BATCH_SIZE,2])\n",
        "        y2[:,1] = 1\n",
        "        \n",
        "        # Generatorのtrain\n",
        "        GAN.train_on_batch(noise_gen, y2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnM4e9_XpcIu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データのロード\n",
        "\n",
        "# サイズを合わせる\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "list_pic_sayashi = []\n",
        "for p in list_pictures('this_is_sayashi'):\n",
        "    list_pic_sayashi.append(load_img(p).resize((100, 100), Image.LANCZOS))\n",
        "\n",
        "list_pic_sayashi_2 = []\n",
        "for p in range(len(list_pic_sayashi)):\n",
        "    list_pic_sayashi_2.append(ImageOps.mirror(list_pic_sayashi[p]))\n",
        "    \n",
        "list_pic_sayashi.extend(list_pic_sayashi_2)\n",
        "\n",
        "X0 = np.empty((len(list_pic_sayashi),100,100,3))\n",
        "Y0 = []\n",
        "\n",
        "#　鞘師の画像(0)\n",
        "for i, picture in enumerate(list_pic_sayashi):\n",
        "    img_is_sayashi = img_to_array(picture)\n",
        "    X0[i,:,:,:] = img_is_sayashi\n",
        "    \n",
        "    Y0.append(0)\n",
        "Y0 = np.array(Y0)\n",
        "list_pic_sayashi[260]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1eCCDyLqRqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# サイズを合わせる\n",
        "from PIL import Image\n",
        "\n",
        "list_pic_sayumi = []\n",
        "for p in list_pictures('this_is_sayumi/this_is_sayumi'):\n",
        "    list_pic_sayumi.append(load_img(p).resize((100, 100), Image.LANCZOS))\n",
        "\n",
        "list_pic_sayumi_2 = []\n",
        "for p in range(len(list_pic_sayumi)):\n",
        "    list_pic_sayumi_2.append(ImageOps.mirror(list_pic_sayumi[p]))\n",
        "\n",
        "list_pic_sayumi.extend(list_pic_sayumi_2)\n",
        "\n",
        "X1 = np.empty((len(list_pic_sayumi),100,100,3))\n",
        "Y1 = []\n",
        "\n",
        "#　道重の画像(1)\n",
        "for i, picture in enumerate(list_pic_sayumi):\n",
        "    img_is_sayumi = img_to_array(picture)\n",
        "    X1[i,:,:,:] = img_is_sayumi\n",
        "    \n",
        "    Y1.append(1)\n",
        "Y1 = np.array(Y1)\n",
        "list_pic_sayumi[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Km1zEXRqVGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# サイズを合わせる\n",
        "from PIL import Image\n",
        "\n",
        "list_pic_karin = []\n",
        "for p in list_pictures('this_is_karin/tihs_is_karin'):\n",
        "    list_pic_karin.append(load_img(p).resize((100, 100), Image.LANCZOS))\n",
        "\n",
        "list_pic_karin_2 = []\n",
        "for p in range(len(list_pic_karin)):\n",
        "    list_pic_karin_2.append(ImageOps.mirror(list_pic_karin[p]))\n",
        "\n",
        "list_pic_karin.extend(list_pic_karin_2)\n",
        "\n",
        "X2 = np.empty((len(list_pic_karin),100,100,3))\n",
        "Y2 = []\n",
        "\n",
        "#　佳林の画像(2)\n",
        "for i, picture in enumerate(list_pic_karin):\n",
        "    img_is_karin = img_to_array(picture)\n",
        "    X2[i,:,:,:] = img_is_karin\n",
        "    \n",
        "    Y2.append(2)\n",
        "Y2 = np.array(Y2)\n",
        "list_pic_karin[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SKKYl6kiqaiv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((X0, X1, X2))\n",
        "array_to_img(X_train[1900])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hRQZNY_bUmnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEoGjn8jpQ9T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# それぞれのネットワークのインスタンスを生成\n",
        "generator = Generator()\n",
        "discriminator = Discriminator(X_train.shape[1:])\n",
        "make_trainable(discriminator, False)\n",
        "GAN = combined_network(generator, discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pi-8bNr83PPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train関数で学習を行うstepを大きくすると学習をより多く行います\n",
        "train(step=20000, BATCH_SIZE=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r2Akrz813Pcm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "x = 3\n",
        "\n",
        "noise = np.random.uniform(0,1,size=[x, 100])\n",
        "generated_images = generator.predict(noise)\n",
        "\n",
        "img = []\n",
        "\n",
        "for i in range(x):\n",
        "    img.append(array_to_img(generated_images[i],scale=True))\n",
        "    img[i].save('img{0}.jpg'.format(str(i)))\n",
        "    files.download('img{0}.jpg'.format(str(i)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I38A0ghu7MOr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator.save('sayashi3g.h5')\n",
        "files.download('sayashi3g.h5')\n",
        "discriminator.save('sayashi3d.h5')\n",
        "files.download('sayashi3d.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I9--EVSVQ1Ba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(step=10000, BATCH_SIZE=32)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}